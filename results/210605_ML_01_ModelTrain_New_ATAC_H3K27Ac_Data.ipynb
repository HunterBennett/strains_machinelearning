{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary:\n",
    "In this notebook I will make 2 new DL CNN models based on active enhancers: one for homeostatic KCs (based on peaks from control C57 KCs) and one for differential peaks in NASH (based on peaks specific for AMLN C57 KCs, with control peaks as background). For the second model I will also adjust the partitioning of data to maximize the amount of data in the training set, by getting rid of a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import sys\n",
    "import random\n",
    "import os\n",
    "import fnmatch\n",
    "import sys\n",
    "\n",
    "#both of these can be imported to python in the terminal in zs-deeplift env\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDirectory = '/home/h1bennet/strains/data/ATAC/control_cohort2/'\n",
    "workingDirectory = '/home/h1bennet//strains_machinelearning/results/00_New_ATAC_H3K27Ac_Model/'\n",
    "if not os.path.isdir(workingDirectory):\n",
    "    os.mkdir(workingDirectory)\n",
    "os.chdir(workingDirectory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_genome(ref_path):\n",
    "    ref_dict = {}\n",
    "    for seq in SeqIO.parse(ref_path, \"fasta\"):\n",
    "        chromID = seq.id\n",
    "        chromSeq = (str(seq.seq)).upper()\n",
    "        ref_dict[chromID] = chromSeq\n",
    "    return ref_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_path = \"/home/zes017/genomes/mm10/mm10.fa\"\n",
    "genomes = load_genome(ref_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BED/peak file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(path, genomes, label, size=500, rep=1, shift=None):\n",
    "    print (\"Scaled to %d\" % (size))\n",
    "    if shift is None:\n",
    "        shifts = size//rep*np.arange(-rep//2+1,rep//2+1)\n",
    "    elif type(shift) is int:\n",
    "        shifts = np.abs(shift)*np.arange(-rep//2+1,rep//2+1)\n",
    "    elif type(shift) is list:\n",
    "        if len(shift) != rep:\n",
    "            raise TypeError(\"Number of shift unequal to replicates\")\n",
    "        shifts = np.array(shift)\n",
    "    if rep == 1 and shift is not None:\n",
    "        random_shift = True\n",
    "        print(\"Random shifting within %s\" % (str(-np.abs(shift))+'~'+str(np.abs(shift))))\n",
    "    else:\n",
    "        random_shift = False\n",
    "        print(\"Generate replicates by shifting %s bp\" % (','.join(shifts.astype(str))))\n",
    "    \n",
    "    data_list = []\n",
    "    for line in open(path):\n",
    "        elems = line.split()\n",
    "        chromID = elems[0]\n",
    "        start, end = int(elems[1]), int(elems[2])\n",
    "        length = end-start\n",
    "        mid = (start+end)//2\n",
    "        for s in shifts:\n",
    "            if random_shift:\n",
    "                new_mid = mid + np.random.choice(np.arange(-np.abs(shift), np.abs(shift)+1))\n",
    "            else:\n",
    "                new_mid = mid + s\n",
    "            start = new_mid - size//2\n",
    "            end = new_mid + size//2\n",
    "            seq = genomes[chromID][start:end]\n",
    "            if len(seq) != size:\n",
    "                continue\n",
    "            data_point = (seq, label, chromID, start, end)\n",
    "            data_list.append(data_point)\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled to 300\n",
      "Generate replicates by shifting 0 bp\n",
      "Scaled to 300\n",
      "Generate replicates by shifting 0 bp\n",
      "37141 37141\n"
     ]
    }
   ],
   "source": [
    "# poised model\n",
    "pos_data_path = \"/home/h1bennet/strains_machinelearning/results/00_New_ATAC_H3K27Ac_Model/bed_files/poised_enhancers.bed\"\n",
    "pos_data_poised = data_prep(pos_data_path, genomes, 1, size=300, rep=1, shift=None)\n",
    "neg_data_path = \"/home/h1bennet/strains_machinelearning/results/00_New_ATAC_H3K27Ac_Model/bg_files/poised_enhancersbg.bed\"\n",
    "neg_data_poised = data_prep(neg_data_path, genomes, 0, size=300, rep=1, shift=None)\n",
    "\n",
    "print(len(pos_data_poised), len(neg_data_poised))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled to 300\n",
      "Generate replicates by shifting 0 bp\n",
      "Scaled to 300\n",
      "Generate replicates by shifting 0 bp\n",
      "36151 36151\n"
     ]
    }
   ],
   "source": [
    "# active model\n",
    "pos_data_active_path = \"/home/h1bennet/strains_machinelearning/results/00_New_ATAC_H3K27Ac_Model/bed_files/active_enhancers.bed\"\n",
    "pos_data_active = data_prep(pos_data_active_path, genomes, 1, size=300, rep=1, shift=None)\n",
    "neg_data_active_path = \"/home/h1bennet/strains_machinelearning/results/00_New_ATAC_H3K27Ac_Model/bg_files/active_enhancersbg.bed\"\n",
    "neg_data_active = data_prep(neg_data_active_path, genomes, 0, size=300, rep=1, shift=None)\n",
    "\n",
    "print(len(pos_data_active), len(neg_data_active))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, train, valid, test):\n",
    "    for data_point in dataset:\n",
    "        chromID = data_point[2]\n",
    "        if chromID == \"chr8\":\n",
    "            valid.append(data_point)\n",
    "        elif chromID == \"chr9\":\n",
    "            test.append(data_point)\n",
    "        else:\n",
    "            train.append(data_point)\n",
    "\n",
    "#version that eliminates the test set\n",
    "def create_dataset2(dataset, train, valid):\n",
    "    for data_point in dataset:\n",
    "        chromID = data_point[2]\n",
    "        if chromID == \"chr8\":\n",
    "            valid.append(data_point)\n",
    "#         elif chromID == \"chr9\":\n",
    "#             test.append(data_point) #just take this out?\n",
    "        else:\n",
    "            train.append(data_point)\n",
    "            \n",
    "def dataset2onehot(dataset, shuffle=True):\n",
    "    nucleotides = [\"A\", \"T\", \"C\", \"G\"]\n",
    "    def seq2onehot(seq):\n",
    "        onehot_list = []\n",
    "        for nuc in seq:\n",
    "            if nuc == \"N\":\n",
    "                onehot = [0.25 for _ in range(len(nucleotides))]\n",
    "                onehot_list.append(onehot)\n",
    "            else:\n",
    "                onehot = [0 for _ in range(len(nucleotides))]\n",
    "                onehot[nucleotides.index(nuc)] = 1\n",
    "                onehot_list.append(onehot)\n",
    "        return onehot_list\n",
    "    \n",
    "    def rc(seq):\n",
    "        return str((Seq(seq)).reverse_complement())\n",
    "    \n",
    "    onehot_dataset = []\n",
    "    for (seq, label, chromID, start, end) in dataset:\n",
    "        onehot_dataset.append((seq2onehot(seq), label, (chromID, start, end, \"+\")))\n",
    "        onehot_dataset.append((seq2onehot(rc(seq)), label, (chromID, start, end, \"-\")))\n",
    "    \n",
    "    if shuffle:\n",
    "        random.shuffle(onehot_dataset)\n",
    "    \n",
    "    x_list, y_list, info_list = [], [], [] \n",
    "    for (x, y, info) in onehot_dataset:\n",
    "        x_list.append(x)\n",
    "        y_list.append(y)\n",
    "        info_list.append(info)\n",
    "    return np.array(x_list), np.array(y_list), info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poised\n",
    "train_raw, valid_raw, test_raw = [], [], []\n",
    "create_dataset(pos_data_poised, train_raw, valid_raw, test_raw)\n",
    "create_dataset(neg_data_poised, train_raw, valid_raw, test_raw)\n",
    "x_train, y_train, info_train = dataset2onehot(train_raw)\n",
    "x_valid, y_valid, info_valid = dataset2onehot(valid_raw)\n",
    "x_test, y_test, info_test = dataset2onehot(test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "(133490, 300, 4)\n",
      "(133490,)\n",
      "Validation set:\n",
      "(7454, 300, 4)\n",
      "(7454,)\n",
      "Testing set:\n",
      "(7620, 300, 4)\n",
      "(7620,)\n"
     ]
    }
   ],
   "source": [
    "print('Training set:')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print('Validation set:')\n",
    "print(x_valid.shape)\n",
    "print(y_valid.shape)\n",
    "print('Testing set:')\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#active\n",
    "train_raw_active, valid_raw_active, test_raw_active = [], [], []\n",
    "create_dataset(pos_data_active, train_raw_active, valid_raw_active, test_raw_active)\n",
    "create_dataset(neg_data_active, train_raw_active, valid_raw_active, test_raw_active)\n",
    "x_train_active, y_train_active, info_train_active = dataset2onehot(train_raw_active)\n",
    "x_valid_active, y_valid_active, info_valid_active = dataset2onehot(valid_raw_active)\n",
    "x_test_active, y_test_active, info_test_active = dataset2onehot(test_raw_active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "(130154, 300, 4)\n",
      "(130154,)\n",
      "Validation set:\n",
      "(7164, 300, 4)\n",
      "(7164, 300, 4)\n",
      "Testing set:\n",
      "(7286, 300, 4)\n",
      "(7286,)\n"
     ]
    }
   ],
   "source": [
    "print('Training set:')\n",
    "print(x_train_active.shape)\n",
    "print(y_train_active.shape)\n",
    "print('Validation set:')\n",
    "print(x_valid_active.shape)\n",
    "print(x_valid_active.shape)\n",
    "print('Testing set:')\n",
    "print(x_test_active.shape)\n",
    "print(y_test_active.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Train model in keras\n",
    "#\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 1\n",
    "seq_size = 300\n",
    "n_channels = 4\n",
    "input_shape = (seq_size, n_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poised Enhancers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/h1bennet/anaconda3/envs/zs-deeplift/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/h1bennet/anaconda3/envs/zs-deeplift/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model structure\n",
    "model = Sequential()\n",
    "# conv1\n",
    "model.add(Conv1D(320, kernel_size=8, strides=1, padding='valid',\n",
    "    kernel_initializer=keras.initializers.TruncatedNormal(stddev=1e-2),\n",
    "    kernel_regularizer=keras.regularizers.l2(5e-7),\n",
    "    bias_initializer=keras.initializers.Constant(value=0),\n",
    "    activity_regularizer=keras.regularizers.l1(1e-8),\n",
    "    input_shape=input_shape, name='conv1'))\n",
    "model.add(BatchNormalization(name = \"bn1\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=4, strides=4, padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# conv2\n",
    "model.add(Conv1D(480, kernel_size=8, strides=1, padding='valid',\n",
    "    kernel_initializer=keras.initializers.TruncatedNormal(stddev=1e-2),\n",
    "    kernel_regularizer=keras.regularizers.l2(5e-7),\n",
    "    bias_initializer=keras.initializers.Constant(value=0),\n",
    "    activity_regularizer=keras.regularizers.l1(1e-8),\n",
    "    name='conv2'))\n",
    "model.add(BatchNormalization(name = \"bn2\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=4, strides=4, padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# conv3\n",
    "model.add(Conv1D(960, kernel_size=8, strides=1, padding='valid',\n",
    "    kernel_initializer=keras.initializers.TruncatedNormal(stddev=1e-2),\n",
    "    kernel_regularizer=keras.regularizers.l2(5e-7),\n",
    "    bias_initializer=keras.initializers.Constant(value=0),\n",
    "    activity_regularizer=keras.regularizers.l1(1e-8),\n",
    "    name='conv3'))\n",
    "model.add(BatchNormalization(name = \"bn3\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# fc1\n",
    "model.add(Dense(925,\n",
    "    kernel_initializer=keras.initializers.TruncatedNormal(stddev=1e-2),\n",
    "    kernel_regularizer=keras.regularizers.l2(5e-7),\n",
    "    bias_initializer=keras.initializers.Constant(value=0),\n",
    "    activity_regularizer=keras.regularizers.l1(1e-8)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# output\n",
    "model.add(Dense(num_classes,\n",
    "    kernel_initializer=keras.initializers.TruncatedNormal(stddev=1e-2),\n",
    "    kernel_regularizer=keras.regularizers.l2(5e-7),\n",
    "    bias_initializer=keras.initializers.Constant(value=0),\n",
    "    activity_regularizer=keras.regularizers.l1(1e-8)))\n",
    "model.add(Activation('sigmoid'))\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def load_from_tf(name):\n",
    "    return tf.train.load_variable(\"/home/zes017/AD/data/AgentBind/benchmarking_dnase/data/model\", name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_layer(\"conv1\").set_weights(\n",
    "    [load_from_tf('conv1/weights/ExponentialMovingAverage'),\n",
    "    load_from_tf('conv1/biases/ExponentialMovingAverage')])\n",
    "model.get_layer(\"conv2\").set_weights(\n",
    "    [load_from_tf('conv2/weights/ExponentialMovingAverage'),\n",
    "    load_from_tf('conv2/biases/ExponentialMovingAverage')])\n",
    "model.get_layer(\"conv3\").set_weights(\n",
    "    [load_from_tf('conv3/weights/ExponentialMovingAverage'),\n",
    "    load_from_tf('conv3/biases/ExponentialMovingAverage')])\n",
    "model.get_layer(\"bn1\").set_weights(\n",
    "    [load_from_tf('conv1/batch_normalization/gamma/ExponentialMovingAverage'),\n",
    "     load_from_tf('conv1/batch_normalization/beta/ExponentialMovingAverage'),\n",
    "    np.zeros(model.get_layer(\"bn1\").weights[2].shape),\n",
    "    np.zeros(model.get_layer(\"bn1\").weights[3].shape)])\n",
    "model.get_layer(\"bn2\").set_weights(\n",
    "    [load_from_tf('conv2/batch_normalization/gamma/ExponentialMovingAverage'),\n",
    "     load_from_tf('conv2/batch_normalization/beta/ExponentialMovingAverage'),\n",
    "    np.zeros(model.get_layer(\"bn2\").weights[2].shape),\n",
    "    np.zeros(model.get_layer(\"bn2\").weights[3].shape)])\n",
    "model.get_layer(\"bn3\").set_weights(\n",
    "    [load_from_tf('conv3/batch_normalization/gamma/ExponentialMovingAverage'),\n",
    "     load_from_tf('conv3/batch_normalization/beta/ExponentialMovingAverage'),\n",
    "    np.zeros(model.get_layer(\"bn3\").weights[2].shape),\n",
    "    np.zeros(model.get_layer(\"bn3\").weights[3].shape)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Enhancer Model (model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model structure (same as prev, but second making a second model)\n",
    "model2 = Sequential()\n",
    "# conv1\n",
    "model2.add(Conv1D(320, kernel_size=8, strides=1, padding='valid',\n",
    "    kernel_initializer=keras.initializers.TruncatedNormal(stddev=1e-2),\n",
    "    kernel_regularizer=keras.regularizers.l2(5e-7),\n",
    "    bias_initializer=keras.initializers.Constant(value=0),\n",
    "    activity_regularizer=keras.regularizers.l1(1e-8),\n",
    "    input_shape=input_shape, name='conv1'))\n",
    "model2.add(BatchNormalization(name = \"bn1\"))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling1D(pool_size=4, strides=4, padding='same'))\n",
    "model2.add(Dropout(0.2))\n",
    "\n",
    "# conv2\n",
    "model2.add(Conv1D(480, kernel_size=8, strides=1, padding='valid',\n",
    "    kernel_initializer=keras.initializers.TruncatedNormal(stddev=1e-2),\n",
    "    kernel_regularizer=keras.regularizers.l2(5e-7),\n",
    "    bias_initializer=keras.initializers.Constant(value=0),\n",
    "    activity_regularizer=keras.regularizers.l1(1e-8),\n",
    "    name='conv2'))\n",
    "model2.add(BatchNormalization(name = \"bn2\"))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling1D(pool_size=4, strides=4, padding='same'))\n",
    "model2.add(Dropout(0.2))\n",
    "\n",
    "# conv3\n",
    "model2.add(Conv1D(960, kernel_size=8, strides=1, padding='valid',\n",
    "    kernel_initializer=keras.initializers.TruncatedNormal(stddev=1e-2),\n",
    "    kernel_regularizer=keras.regularizers.l2(5e-7),\n",
    "    bias_initializer=keras.initializers.Constant(value=0),\n",
    "    activity_regularizer=keras.regularizers.l1(1e-8),\n",
    "    name='conv3'))\n",
    "model2.add(BatchNormalization(name = \"bn3\"))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "\n",
    "model2.add(Flatten())\n",
    "\n",
    "# fc1\n",
    "model2.add(Dense(925,\n",
    "    kernel_initializer=keras.initializers.TruncatedNormal(stddev=1e-2),\n",
    "    kernel_regularizer=keras.regularizers.l2(5e-7),\n",
    "    bias_initializer=keras.initializers.Constant(value=0),\n",
    "    activity_regularizer=keras.regularizers.l1(1e-8)))\n",
    "model2.add(Activation('relu'))\n",
    "\n",
    "# output\n",
    "model2.add(Dense(num_classes,\n",
    "    kernel_initializer=keras.initializers.TruncatedNormal(stddev=1e-2),\n",
    "    kernel_regularizer=keras.regularizers.l2(5e-7),\n",
    "    bias_initializer=keras.initializers.Constant(value=0),\n",
    "    activity_regularizer=keras.regularizers.l1(1e-8)))\n",
    "model2.add(Activation('sigmoid'))\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def load_from_tf(name):\n",
    "    return tf.train.load_variable(\"/home/zes017/AD/data/AgentBind/benchmarking_dnase/data/model\", name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.get_layer(\"conv1\").set_weights(\n",
    "    [load_from_tf('conv1/weights/ExponentialMovingAverage'),\n",
    "    load_from_tf('conv1/biases/ExponentialMovingAverage')])\n",
    "model2.get_layer(\"conv2\").set_weights(\n",
    "    [load_from_tf('conv2/weights/ExponentialMovingAverage'),\n",
    "    load_from_tf('conv2/biases/ExponentialMovingAverage')])\n",
    "model2.get_layer(\"conv3\").set_weights(\n",
    "    [load_from_tf('conv3/weights/ExponentialMovingAverage'),\n",
    "    load_from_tf('conv3/biases/ExponentialMovingAverage')])\n",
    "model2.get_layer(\"bn1\").set_weights(\n",
    "    [load_from_tf('conv1/batch_normalization/gamma/ExponentialMovingAverage'),\n",
    "     load_from_tf('conv1/batch_normalization/beta/ExponentialMovingAverage'),\n",
    "    np.zeros(model2.get_layer(\"bn1\").weights[2].shape),\n",
    "    np.zeros(model2.get_layer(\"bn1\").weights[3].shape)])\n",
    "model2.get_layer(\"bn2\").set_weights(\n",
    "    [load_from_tf('conv2/batch_normalization/gamma/ExponentialMovingAverage'),\n",
    "     load_from_tf('conv2/batch_normalization/beta/ExponentialMovingAverage'),\n",
    "    np.zeros(model2.get_layer(\"bn2\").weights[2].shape),\n",
    "    np.zeros(model2.get_layer(\"bn2\").weights[3].shape)])\n",
    "model2.get_layer(\"bn3\").set_weights(\n",
    "    [load_from_tf('conv3/batch_normalization/gamma/ExponentialMovingAverage'),\n",
    "     load_from_tf('conv3/batch_normalization/beta/ExponentialMovingAverage'),\n",
    "    np.zeros(model2.get_layer(\"bn3\").weights[2].shape),\n",
    "    np.zeros(model2.get_layer(\"bn3\").weights[3].shape)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('./model_weights/'):\n",
    "    os.mkdir('./model_weights/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poised\n",
    "Set names: x_train, y_train, x_valid, y_valid, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/h1bennet/anaconda3/envs/zs-deeplift/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/h1bennet/anaconda3/envs/zs-deeplift/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 133490 samples, validate on 7454 samples\n",
      "Epoch 1/20\n",
      "133490/133490 [==============================] - 439s 3ms/step - loss: 0.5975 - accuracy: 0.8312 - val_loss: 0.5048 - val_accuracy: 0.8640\n",
      "Epoch 2/20\n",
      "133490/133490 [==============================] - 438s 3ms/step - loss: 0.5392 - accuracy: 0.8442 - val_loss: 0.4790 - val_accuracy: 0.8658\n",
      "Epoch 3/20\n",
      "133490/133490 [==============================] - 438s 3ms/step - loss: 0.4945 - accuracy: 0.8513 - val_loss: 0.4768 - val_accuracy: 0.8575\n",
      "Epoch 4/20\n",
      "133490/133490 [==============================] - 441s 3ms/step - loss: 0.4728 - accuracy: 0.8554 - val_loss: 0.4369 - val_accuracy: 0.8731\n",
      "Epoch 5/20\n",
      "133490/133490 [==============================] - 440s 3ms/step - loss: 0.4638 - accuracy: 0.8563 - val_loss: 0.4263 - val_accuracy: 0.8728\n",
      "Epoch 6/20\n",
      "133490/133490 [==============================] - 440s 3ms/step - loss: 0.4551 - accuracy: 0.8563 - val_loss: 0.4255 - val_accuracy: 0.8764\n",
      "Epoch 7/20\n",
      "133490/133490 [==============================] - 439s 3ms/step - loss: 0.4478 - accuracy: 0.8584 - val_loss: 0.4109 - val_accuracy: 0.8752\n",
      "Epoch 8/20\n",
      "133490/133490 [==============================] - 440s 3ms/step - loss: 0.4430 - accuracy: 0.8599 - val_loss: 0.4166 - val_accuracy: 0.8645\n",
      "Epoch 9/20\n",
      "133490/133490 [==============================] - 438s 3ms/step - loss: 0.4374 - accuracy: 0.8601 - val_loss: 0.4042 - val_accuracy: 0.8748\n",
      "Epoch 10/20\n",
      "133490/133490 [==============================] - 439s 3ms/step - loss: 0.4323 - accuracy: 0.8615 - val_loss: 0.3902 - val_accuracy: 0.8822\n",
      "Epoch 11/20\n",
      "133490/133490 [==============================] - 441s 3ms/step - loss: 0.4291 - accuracy: 0.8627 - val_loss: 0.4081 - val_accuracy: 0.8721\n",
      "Epoch 12/20\n",
      "133490/133490 [==============================] - 441s 3ms/step - loss: 0.4264 - accuracy: 0.8625 - val_loss: 0.3964 - val_accuracy: 0.8756\n",
      "Epoch 13/20\n",
      "133490/133490 [==============================] - 438s 3ms/step - loss: 0.4215 - accuracy: 0.8634 - val_loss: 0.4083 - val_accuracy: 0.8703\n",
      "Epoch 14/20\n",
      "133490/133490 [==============================] - 438s 3ms/step - loss: 0.4206 - accuracy: 0.8639 - val_loss: 0.3883 - val_accuracy: 0.8763\n",
      "Epoch 15/20\n",
      "133490/133490 [==============================] - 440s 3ms/step - loss: 0.4218 - accuracy: 0.8609 - val_loss: 0.3808 - val_accuracy: 0.8819\n",
      "Epoch 16/20\n",
      "133490/133490 [==============================] - 440s 3ms/step - loss: 0.4181 - accuracy: 0.8629 - val_loss: 0.3793 - val_accuracy: 0.8825\n",
      "Epoch 17/20\n",
      "133490/133490 [==============================] - 439s 3ms/step - loss: 0.4161 - accuracy: 0.8620 - val_loss: 0.3937 - val_accuracy: 0.8731\n",
      "Epoch 18/20\n",
      "133490/133490 [==============================] - 442s 3ms/step - loss: 0.4128 - accuracy: 0.8636 - val_loss: 0.3764 - val_accuracy: 0.8794\n",
      "Epoch 19/20\n",
      "133490/133490 [==============================] - 443s 3ms/step - loss: 0.4123 - accuracy: 0.8642 - val_loss: 0.3816 - val_accuracy: 0.8823\n",
      "Epoch 20/20\n",
      "133490/133490 [==============================] - 441s 3ms/step - loss: 0.4070 - accuracy: 0.8654 - val_loss: 0.3854 - val_accuracy: 0.8770\n",
      "\n",
      "history dict: {'val_loss': [0.5048477362540505, 0.47899379301141537, 0.4767677412856383, 0.43688060366055076, 0.42625471632123024, 0.4254730482315102, 0.410921022251972, 0.416647200877717, 0.4042359336247097, 0.39022672813668596, 0.40810096119951556, 0.3964434479032664, 0.40827298164367676, 0.38830207575733294, 0.3808146208116891, 0.37931693547415546, 0.3937197916383618, 0.3764096085079112, 0.38159723194060646, 0.3854483451013562], 'val_accuracy': [0.863965630531311, 0.8658438324928284, 0.8575261831283569, 0.8730883002281189, 0.8728199601173401, 0.8764421939849854, 0.8752347826957703, 0.8645022511482239, 0.8748323321342468, 0.882210910320282, 0.8721491694450378, 0.8756372332572937, 0.8702709674835205, 0.876308023929596, 0.8819425702095032, 0.882479190826416, 0.8730883002281189, 0.8793936371803284, 0.8823450207710266, 0.8769788146018982], 'loss': [0.5975227947922376, 0.5391745056442683, 0.49454891393672074, 0.4728295868742787, 0.4638315941124018, 0.4550846218031367, 0.4478032255763909, 0.443010184415959, 0.43736756791987397, 0.4323430713477389, 0.4290584370142262, 0.4264026461723494, 0.4215193863767516, 0.4206400433049433, 0.42177854179309027, 0.41808156367901766, 0.4161185918831988, 0.4128097202967361, 0.4122706649280932, 0.40700089468456974], 'accuracy': [0.83120084, 0.84420556, 0.8513147, 0.85537493, 0.8563338, 0.8563039, 0.8583789, 0.8599146, 0.8601019, 0.8614653, 0.8626788, 0.86249906, 0.863428, 0.8639149, 0.8609334, 0.862941, 0.86200464, 0.86360025, 0.86415464, 0.8653532]}\n",
      "[0.5232871983884424, 0.8026351928710938]\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "        optimizer=keras.optimizers.Adam(lr=1e-2),\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=x_train, y=y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=20,\n",
    "            verbose=1,\n",
    "            validation_data=(x_valid, y_valid))\n",
    "score = model.evaluate(x_test_active, y_test_active, verbose=0, batch_size=batch_size)\n",
    "print('\\nhistory dict:', history.history)\n",
    "print(score)\n",
    "\n",
    "keras_model_weights = workingDirectory+\"/model_weights/modelWeights_300bp_C57BL6J_poised_epo20_RandomShift0bp.h5\"\n",
    "keras_model_json = workingDirectory+\"/model_weights/modelWeights_300bp_C57BL6J_poised_epo20_RandomShift0bp.json\"\n",
    "\n",
    "json_string = model.to_json() # architecture\n",
    "with open(keras_model_json, 'w') as json_file:\n",
    "    json_file.write(json_string)\n",
    "model.save_weights(keras_model_weights) # weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9503915895061728\n",
      "Accuracy: 0.8695538057742782\n"
     ]
    }
   ],
   "source": [
    "##Load model\n",
    "from keras.models import model_from_json\n",
    "\n",
    "model_weights = workingDirectory+\"/model_weights/modelWeights_300bp_C57BL6J_poised_epo20_RandomShift0bp.h5\"\n",
    "model_json = workingDirectory+\"/model_weights/modelWeights_300bp_C57BL6J_poised_epo20_RandomShift0bp.json\"\n",
    "\n",
    "model = model_from_json(open(model_json).read())\n",
    "model.load_weights(model_weights)\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "        optimizer=keras.optimizers.Adam(lr=1e-2),\n",
    "        metrics=['accuracy'])\n",
    "# model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "preds = model.predict(x_test).flatten()\n",
    "\n",
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, preds, pos_label=1)\n",
    "print('AUC:', metrics.auc(fpr, tpr))\n",
    "print('Accuracy:', metrics.accuracy_score(y_test, (preds>0.5)*1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active\n",
    "Set names: x_train_active, y_train_active, x_valid_active, y_valid_active, x_test_active, y_test_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/h1bennet/anaconda3/envs/zs-deeplift/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/h1bennet/anaconda3/envs/zs-deeplift/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 130154 samples, validate on 7164 samples\n",
      "Epoch 1/20\n",
      "130154/130154 [==============================] - 417s 3ms/step - loss: 0.7184 - accuracy: 0.7689 - val_loss: 0.6860 - val_accuracy: 0.7824\n",
      "Epoch 2/20\n",
      "130154/130154 [==============================] - 416s 3ms/step - loss: 0.6568 - accuracy: 0.7804 - val_loss: 0.5870 - val_accuracy: 0.8058\n",
      "Epoch 3/20\n",
      "130154/130154 [==============================] - 415s 3ms/step - loss: 0.6072 - accuracy: 0.7877 - val_loss: 0.5613 - val_accuracy: 0.8054\n",
      "Epoch 4/20\n",
      "130154/130154 [==============================] - 414s 3ms/step - loss: 0.5782 - accuracy: 0.7914 - val_loss: 0.5356 - val_accuracy: 0.8116\n",
      "Epoch 5/20\n",
      "130154/130154 [==============================] - 416s 3ms/step - loss: 0.5562 - accuracy: 0.7956 - val_loss: 0.5287 - val_accuracy: 0.8051\n",
      "Epoch 6/20\n",
      "130154/130154 [==============================] - 415s 3ms/step - loss: 0.5451 - accuracy: 0.7947 - val_loss: 0.5321 - val_accuracy: 0.7913\n",
      "Epoch 7/20\n",
      "130154/130154 [==============================] - 416s 3ms/step - loss: 0.5352 - accuracy: 0.7988 - val_loss: 0.5266 - val_accuracy: 0.8049\n",
      "Epoch 8/20\n",
      "130154/130154 [==============================] - 414s 3ms/step - loss: 0.5291 - accuracy: 0.7973 - val_loss: 0.5182 - val_accuracy: 0.8009\n",
      "Epoch 9/20\n",
      "130154/130154 [==============================] - 439s 3ms/step - loss: 0.5215 - accuracy: 0.8002 - val_loss: 0.5024 - val_accuracy: 0.8118\n",
      "Epoch 10/20\n",
      "130154/130154 [==============================] - 481s 4ms/step - loss: 0.5191 - accuracy: 0.8004 - val_loss: 0.4999 - val_accuracy: 0.8054\n",
      "Epoch 11/20\n",
      "130154/130154 [==============================] - 440s 3ms/step - loss: 0.5183 - accuracy: 0.7986 - val_loss: 0.5013 - val_accuracy: 0.8032\n",
      "Epoch 12/20\n",
      "130154/130154 [==============================] - 444s 3ms/step - loss: 0.5137 - accuracy: 0.7989 - val_loss: 0.4890 - val_accuracy: 0.8109\n",
      "Epoch 13/20\n",
      "130154/130154 [==============================] - 417s 3ms/step - loss: 0.5112 - accuracy: 0.8004 - val_loss: 0.5097 - val_accuracy: 0.8030\n",
      "Epoch 14/20\n",
      "130154/130154 [==============================] - 424s 3ms/step - loss: 0.5115 - accuracy: 0.8004 - val_loss: 0.4864 - val_accuracy: 0.8106\n",
      "Epoch 15/20\n",
      "130154/130154 [==============================] - 445s 3ms/step - loss: 0.5108 - accuracy: 0.8003 - val_loss: 0.4857 - val_accuracy: 0.8110\n",
      "Epoch 16/20\n",
      "130154/130154 [==============================] - 448s 3ms/step - loss: 0.5096 - accuracy: 0.8021 - val_loss: 0.5108 - val_accuracy: 0.8008\n",
      "Epoch 17/20\n",
      "130154/130154 [==============================] - 446s 3ms/step - loss: 0.5084 - accuracy: 0.8022 - val_loss: 0.5127 - val_accuracy: 0.7923\n",
      "Epoch 18/20\n",
      "130154/130154 [==============================] - 439s 3ms/step - loss: 0.5079 - accuracy: 0.8008 - val_loss: 0.4920 - val_accuracy: 0.8050\n",
      "Epoch 19/20\n",
      "130154/130154 [==============================] - 442s 3ms/step - loss: 0.5034 - accuracy: 0.8031 - val_loss: 0.4788 - val_accuracy: 0.8149\n",
      "Epoch 20/20\n",
      "130154/130154 [==============================] - 447s 3ms/step - loss: 0.5008 - accuracy: 0.8028 - val_loss: 0.4876 - val_accuracy: 0.8071\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "You must compile a model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-d467f513bd3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             validation_data=(x_valid_active, y_valid_active))\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mscore2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_active\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_active\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nhistory dict:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/h1bennet/anaconda3/envs/zs-deeplift/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1347\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1350\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/h1bennet/anaconda3/envs/zs-deeplift/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m                 raise RuntimeError('You must compile a model before '\n\u001b[0m\u001b[1;32m    509\u001b[0m                                    \u001b[0;34m'training/testing. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m                                    'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You must compile a model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "model2.compile(loss=keras.losses.binary_crossentropy,\n",
    "        optimizer=keras.optimizers.Adam(lr=1e-2),\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "history2 = model2.fit(x=x_train_active, y=y_train_active,\n",
    "            batch_size=batch_size,\n",
    "            epochs=20,\n",
    "            verbose=1,\n",
    "            validation_data=(x_valid_active, y_valid_active))\n",
    "\n",
    "score2 = model2.evaluate(x_test_active, y_test_active, verbose=0, batch_size=batch_size)\n",
    "print('\\nhistory dict:', history2.history)\n",
    "print(score2)\n",
    "\n",
    "#instead saved here initially and then moved to ^ folder\n",
    "keras_model_weights2 = workingDirectory+\"/model_weights/modelWeights_300bp_C57BL6J_active_epo20_RandomShift0bp.h5\"\n",
    "keras_model_json2 = workingDirectory+\"/model_weights/modelWeights_300bp_C57BL6J_active_epo20_RandomShift0bp.json\"\n",
    "\n",
    "json_string = model2.to_json() # architecture\n",
    "with open(keras_model_json2, 'w') as json_file:\n",
    "    json_file.write(json_string)\n",
    "model2.save_weights(keras_model_weights2) # weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "history dict: {'val_loss': [0.6860448426204577, 0.5870248079632727, 0.5612665394509324, 0.5355781432239122, 0.528744388332186, 0.5321243085853219, 0.5265512655128786, 0.5181853470024884, 0.5023681396282564, 0.49987501739656903, 0.5012673253390059, 0.4890247217807472, 0.5096842930810802, 0.48638056330944424, 0.4856719158003278, 0.5107910407115334, 0.5127159621647654, 0.4919619049059486, 0.4787564926277919, 0.4876274098769571], 'val_accuracy': [0.7823841571807861, 0.8058347105979919, 0.8054159879684448, 0.8115577697753906, 0.8051367998123169, 0.7913177013397217, 0.804857611656189, 0.800949215888977, 0.8118369579315186, 0.8054159879684448, 0.8031826019287109, 0.8108598589897156, 0.803043007850647, 0.8105806708335876, 0.8109994530677795, 0.8008096218109131, 0.7922948002815247, 0.8049972057342529, 0.8149078488349915, 0.8070909976959229], 'loss': [0.718446445186285, 0.6568286399579945, 0.6072387490121287, 0.5781779678873521, 0.556217206640572, 0.5450509168238672, 0.5351680436285207, 0.5291276700782217, 0.521514738333464, 0.5191044942068204, 0.5182915407460329, 0.5136595939367898, 0.5112097434043401, 0.511467261264072, 0.5108229815740112, 0.5095576412209515, 0.5083898782546005, 0.5078637312312838, 0.5034439236551699, 0.5008370823830639], 'accuracy': [0.7689199, 0.7804063, 0.78765154, 0.7913933, 0.7955883, 0.79469705, 0.7987999, 0.7972556, 0.8001675, 0.8004364, 0.7985617, 0.79889977, 0.8003903, 0.80042875, 0.8002981, 0.80208063, 0.80216515, 0.8008206, 0.8031102, 0.8027798]}\n",
      "[0.47481932760004875, 0.8140268921852112]\n"
     ]
    }
   ],
   "source": [
    "score2 = model2.evaluate(x_test_active, y_test_active, verbose=0, batch_size=batch_size)\n",
    "print('\\nhistory dict:', history2.history)\n",
    "print(score2)\n",
    "\n",
    "#instead saved here initially and then moved to ^ folder\n",
    "keras_model_weights2 = workingDirectory+\"/model_weights/modelWeights_300bp_C57BL6J_active_epo20_RandomShift0bp.h5\"\n",
    "keras_model_json2 = workingDirectory+\"/model_weights/modelWeights_300bp_C57BL6J_active_epo20_RandomShift0bp.json\"\n",
    "\n",
    "json_string = model2.to_json() # architecture\n",
    "with open(keras_model_json2, 'w') as json_file:\n",
    "    json_file.write(json_string)\n",
    "model2.save_weights(keras_model_weights2) # weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9019286253828798\n",
      "Accuracy: 0.8140269009058468\n"
     ]
    }
   ],
   "source": [
    "##Load model\n",
    "from keras.models import model_from_json\n",
    "\n",
    "model_active_weights = workingDirectory+\"/model_weights/modelWeights_300bp_C57BL6J_active_epo20_RandomShift0bp.h5\"\n",
    "model_active_json = workingDirectory+\"/model_weights/modelWeights_300bp_C57BL6J_active_epo20_RandomShift0bp.json\"\n",
    "\n",
    "model_active = model_from_json(open(model_active_json).read())\n",
    "model_active.load_weights(model_active_weights)\n",
    "model_active.compile(loss=keras.losses.binary_crossentropy,\n",
    "        optimizer=keras.optimizers.Adam(lr=1e-2),\n",
    "        metrics=['accuracy'])\n",
    "# model_active.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "preds_active = model_active.predict(x_test_active).flatten()\n",
    "\n",
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test_active, preds_active, pos_label=1)\n",
    "print('AUC:', metrics.auc(fpr, tpr))\n",
    "print('Accuracy:', metrics.accuracy_score(y_test_active, (preds_active>0.5)*1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note from Zeyang: \"Watch for the validation loss and training loss while you train the AMLN model. If the training loss keeps dropping while the validation loss becomes larger and larger, the model likely overfits.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Loss and Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    }
   ],
   "source": [
    "print(history2.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6860448426204577, 0.5870248079632727, 0.5612665394509324, 0.5355781432239122, 0.528744388332186, 0.5321243085853219, 0.5265512655128786, 0.5181853470024884, 0.5023681396282564, 0.49987501739656903, 0.5012673253390059, 0.4890247217807472, 0.5096842930810802, 0.48638056330944424, 0.4856719158003278, 0.5107910407115334, 0.5127159621647654, 0.4919619049059486, 0.4787564926277919, 0.4876274098769571]\n"
     ]
    }
   ],
   "source": [
    "print(history2.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.lineplot(x=range(20),y=history2.history['loss'])\n",
    "#g.set_ylabels(\"Survived\")\n",
    "#g.set_axis_labels(\"Epochs\", \"Validation Loss\")\n",
    "g.set_xlabel(\"Epochs\")\n",
    "g.set_ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Validation Loss')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.lineplot(x=range(20),y=history2.history['val_loss'])\n",
    "#g.set_ylabels(\"Survived\")\n",
    "#g.set_axis_labels(\"Epochs\", \"Validation Loss\")\n",
    "g.set_xlabel(\"Epochs\")\n",
    "g.set_ylabel(\"Validation Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-82032a72049e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#g.set_ylabels(\"Survived\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#g.set_axis_labels(\"Epochs\", \"Validation Loss\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epochs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "g = sns.lineplot(x=range(20),y=history.history['loss'])\n",
    "#g.set_ylabels(\"Survived\")\n",
    "#g.set_axis_labels(\"Epochs\", \"Validation Loss\")\n",
    "g.set_xlabel(\"Epochs\")\n",
    "g.set_ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lineplot(x=range(20),y=history.history['val_loss'])\n",
    "#g.set_ylabels(\"Survived\")\n",
    "#g.set_axis_labels(\"Epochs\", \"Validation Loss\")\n",
    "g.set_xlabel(\"Epochs\")\n",
    "g.set_ylabel(\"Validation Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zs-deeplift",
   "language": "python",
   "name": "zs-deeplift"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
